
local vocab_cfg = {
    "type":"vocab",
    "path": "./wd/vocab.txt"
    };

local strtensor = {
    "type": "label_sent2tensor",
    "vocab":vocab_cfg,
    "tokenizer":{
        "type": "space_tokenizer"
    }, 
    "max_len": 80, 
    "with_lable":false
};

local reader = {
    "type": "text_line_reader"
};


{
    "type":"lm_trainer",
    "vocab": vocab_cfg,
    "train_dataset":{
        "type": "iter_text_dataset",
        "inputs": "./wd/zh_train.txt", 
        "str2tensor_fn": strtensor,
        "read_fn": reader
    },
    "valid_dataset":{
        "type": "iter_text_dataset",
        "inputs": "./wd/zh_valid.txt", 
        "str2tensor_fn": strtensor,
        "read_fn": reader
    },
   
    "model": {
        "type": "bert_lm",
        "vocab": vocab_cfg,

    },
    
    "out_path":"out",

    "train_params":{
        "gpus": 1,
        "auto_select_gpus":true,
        
        "accelerator": "ddp",
        "max_epochs":1,
        "val_check_interval": 200,
        "accumulate_grad_batches": 4,
        "gradient_clip_val": 5.0
    }
}
